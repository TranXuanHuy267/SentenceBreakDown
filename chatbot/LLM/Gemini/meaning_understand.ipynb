{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. refer to a specific tone or frequency\n",
      "------------------------------\n",
      "The violin's high-pitched melody reached an earsplitting crescendo.\n",
      "------------------------------\n",
      "1. The symphony's opening notes reached a captivating pitch, setting the tone for the performance.\n",
      "2. The soprano's voice soared to a high pitch during the aria, bringing the audience to tears.\n",
      "3. The guitarist carefully tuned his strings to achieve the perfect pitch for the song.\n",
      "4. The whistle's piercing pitch signaled the start of the football game.\n",
      "5. The choir harmonized perfectly on the sustained pitch, creating a celestial atmosphere.\n",
      "------------------------------\n",
      "The soprano's voice soared to a high ___ during the aria, bringing the audience to tears.\n",
      "Answer: C\n",
      "The guitarist carefully tuned his strings to achieve the perfect ___ for the song.\n",
      "Answer: Intonation\n",
      "The whistle's piercing ___ signaled the start of the football game.\n",
      "Answer: shriek\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "api_key = \"AIzaSyAkwVWJqOPPAIPYKctH9Y8XuVHrR9I5JwQ\"\n",
    "url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={api_key}\";\n",
    "\n",
    "safetySettings =  [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def qa_gemini(question, session):\n",
    "    \n",
    "    payload = json.dumps({\n",
    "      \"contents\": [\n",
    "        {\n",
    "          \"parts\": [\n",
    "            {\n",
    "              \"text\": question\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"safetySettings\": safetySettings,\n",
    "    })\n",
    "    headers = {\n",
    "      'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = session.request(\"POST\", url, headers=headers, data=payload)\n",
    "    return response\n",
    "\n",
    "def multiplechoice(question, session, options):\n",
    "    options += [\"Other\"]\n",
    "    prompt = \"\"\"Which one have the relevant meaning with the question:\"\"\"+question+\"\\n\".join([str(i+1)+\". \"+option.strip() for i, option in enumerate(options)])\n",
    "    response = qa_gemini(prompt, session)\n",
    "    a = json.loads(response.text)\n",
    "    if 'candidates' in a.keys():\n",
    "        answer = a['candidates'][0]['content']['parts'][0]['text']\n",
    "    else:\n",
    "        answer = \"Connection error!!!\"\n",
    "    return answer\n",
    "\n",
    "def create_sentence(word, session, meaning):\n",
    "    prompt = \"\"\"Create 1 sentences which contain the following word and have the following meaning in the context of each sentence:\\nWord: \"\"\"+word+\" \\nMeaning: \"+meaning+\" \"\n",
    "    response = qa_gemini(prompt, session)\n",
    "    a = json.loads(response.text)\n",
    "    if 'candidates' in a.keys():\n",
    "        answer = a['candidates'][0]['content']['parts'][0]['text']\n",
    "    else:\n",
    "        answer = \"Connection error!!!\"\n",
    "    return answer\n",
    "\n",
    "def create_quiz(word, session, meaning):\n",
    "    prompt = \"\"\"Create 5 sentences which contain the following word, have the following meaning in the context of each sentence, no other word can replace this word in the context of this sentence:\\nWord: \"\"\"+word+\" \\nMeaning: \"+meaning+\" \"\n",
    "    response = qa_gemini(prompt, session)\n",
    "    a = json.loads(response.text)\n",
    "    if 'candidates' in a.keys():\n",
    "        answer = a['candidates'][0]['content']['parts'][0]['text']\n",
    "    else:\n",
    "        answer = \"Connection error!!!\"\n",
    "    return answer\n",
    "\n",
    "\n",
    "def quiz_to_question(word, quiz, best_quiz):\n",
    "    word = \" \" + word.strip() + \" \"\n",
    "    list_qz = quiz.split('\\n')\n",
    "    list_qz = [i[i.index('.')+1:].strip() if '.' in i else i for i in list_qz]\n",
    "    list_qz.append(best_quiz)\n",
    "    list_question = [i.replace(word, \" ___ \") for i in list_qz if word in i]\n",
    "    return list_question\n",
    "    \n",
    "def solve_question(session, question):\n",
    "    prompt = \"\"\"Fill in the blank to complete the following sentence:\\nSentence: \"\"\"+question+\"\"\"\\nAnswer:\"\"\"\n",
    "    response = qa_gemini(prompt, session)\n",
    "    a = json.loads(response.text)\n",
    "    if 'candidates' in a.keys():\n",
    "        answer = a['candidates'][0]['content']['parts'][0]['text']\n",
    "    else:\n",
    "        answer = \"Connection error!!!\"\n",
    "    return answer\n",
    "\n",
    "if __name__=='__main__':\n",
    "    import requests\n",
    "    requests.packages.urllib3.disable_warnings() \n",
    "    session = requests.Session()\n",
    "    session.verify = False\n",
    "    word = \"pitch\"\n",
    "    query = \"something\"\n",
    "    options = [\"refer to a specific tone or frequency\", \"football pitch\"]\n",
    "    answer = multiplechoice(question=query, session=session, options=options)\n",
    "    answer_content = answer[answer.index('.')+1:].strip() if '.' in answer else answer\n",
    "    print(answer)\n",
    "    print('-'*30)\n",
    "    if \"Other\" not in answer_content:\n",
    "        best_quiz = create_sentence(word, session, answer_content)\n",
    "        print(best_quiz)\n",
    "    print('-'*30)\n",
    "    if \"Other\" not in answer_content:\n",
    "        quiz = create_quiz(word, session, answer_content)\n",
    "        print(quiz)\n",
    "    print('-'*30)\n",
    "    questions = quiz_to_question(word, quiz, best_quiz)\n",
    "    for question in questions:\n",
    "        answer = solve_question(session, question)\n",
    "        print(question+\"\\nAnswer: \"+answer)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tranxuanhuy/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"\"\"This is a sample sentence,\n",
    "\t\t\t\tshowing off the stop words filtration.\"\"\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "# converts the words in word_tokens to lower case and then checks whether \n",
    "#they are present in stop_words or not\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#with no lower case conversion\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "\tif w not in stop_words:\n",
    "\t\tfiltered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document: This is a sample document. - BM25 Score: 0.8834385274179376\n",
      "Document: Yet another document example, similar to the others. - BM25 Score: 0.7034170916422069\n",
      "Document: Another example document. - BM25 Score: 0.0\n",
      "Document: This is just a test document. - BM25 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Sample documents\n",
    "documents = [\n",
    "    \"This is a sample document.\",\n",
    "    \"Another example document.\",\n",
    "    \"Yet another document example, similar to the others.\",\n",
    "    \"This is just a test document.\"\n",
    "]\n",
    "\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [doc.split() for doc in documents]\n",
    "\n",
    "# Create BM25 object\n",
    "bm25 = BM25Okapi(tokenized_documents)\n",
    "\n",
    "# Sample query\n",
    "query = \"sample document\"\n",
    "\n",
    "# Tokenize the query\n",
    "tokenized_query = query.split()\n",
    "\n",
    "# Get BM25 scores for the documents\n",
    "bm25_scores = bm25.get_scores(tokenized_query)\n",
    "\n",
    "# Sort documents based on scores\n",
    "sorted_results = sorted(zip(documents, bm25_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print ranked documents\n",
    "for doc, score in sorted_results:\n",
    "    print(f\"Document: {doc} - BM25 Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in /Users/tranxuanhuy/anaconda3/lib/python3.11/site-packages (from rank_bm25) (1.24.3)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
